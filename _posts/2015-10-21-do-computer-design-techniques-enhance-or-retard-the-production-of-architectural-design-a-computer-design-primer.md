---
layout: post
title: Dissertation (what I thought 10 years ago)
date: 2015-10-21 20:46:59.000000000 +11:00
type: post
published: true
status: publish
categories: []
tags:
- Asymptote
- computers
- Frank Gehry
- Greg Lynn
- Manual De Landa
- Marcos Novak
- nox
- The Emergence And Design Group
- The Smart Geometry Group
- undergraduate
- writing
description:
meta:
  _publicize_facebook_user: http://www.facebook.com/541400612
  _publicize_twitter_user: "@notionparallax"

---
<style type="text/css">
  .small-caps {
    font-variant:
    small-caps; 
  }
  p.inter-paragraph {
        font-size: 130%;
        padding: 0 10% 0 10%;
        line-height: 1.5;
        background-color: aliceblue;
        margin: 30px 0;
    }
</style>
<p>This is my undergraduate dissertation. I wrote it over 10 years ago so a lot of things have changed. I think the thing that has changed the most is me! I cringe a bit at the wildly overconfident statements I make, and the referencing is <em>terrible</em>. As tempting as it is to correct it, the person who wrote it doesn't exist any more so I've left it as is. There might also be some errors in formatting that have come in from the InDesign export process, mostly small caps becoming lower case.</p>
<p>If you want the original PDF then there's a <a href="https://drive.google.com/file/d/0BwIWT_wqd-VmbTNOa1hqN3JmMzQ/view?usp=sharing">screen res copy here(8mb)</a> and a <a href="https://drive.google.com/file/d/0BwIWT_wqd-VmbjJibXlKRmwxVU0/view?usp=sharing">full res copy here (73mb)</a>. Click <em>more</em> to get in on the html version, but it's a pretty heavy page so don't do it on the bus!</p>
<p><a href="/wordpress/wp-content/uploads/2015/10/dissertation_Page_01.png" rel="attachment wp-att-1949"><img class="alignnone size-full wp-image-1949" src="{{ site.baseurl }}/assets/dissertation_Page_01.png" alt="dissertation_Page_01" /></a><br />
<!--more--></p>
<hr />
<ul>
<li><a href="#frank">Frank Gehry</a></li>
<li><span class="small-caps"><a href="#nox">nox</a></span></li>
<li><a href="#emergence">The Emergence And Design Group</a></li>
<li><a href="#sg">The Smart Geometry Group</a></li>
<li><a href="#novak">Marcos Novak</a></li>
<li><a href="#asymptote">Asymptote</a></li>
<li><a href="#greg">Greg Lynn</a></li>
<li><a href="#conclusion">Conclusion</a></li>
<li><a href="#glossary">Glossary</a></li>
</ul>
<p><img class="alignnone size-full wp-image-1947" src="{{ site.baseurl }}/assets/04-chepstow-castle.jpg" alt="04-chepstow-castle" /></p>
<p>This text will explore the use of computers in the design process, their move up the hierarchy of design tools, and what their new position higher up that hierarchy is making possible in terms of exotic form finding. Instead of merely producing purely sculptural forms, new computing technologies allow structural considerations to work symbiotically to produce true elegance in the architecture they produce when wielded by today’s architects.</p>
<p>The exponentially increasing processing speed of computers[1. In 1965 Gordon Moore predicted that the number of transistors per integrated circuit would double every 2 years. This has remained true ever since, however we are reaching the limits of our current manufacturing techniques capacity, but this has happened before and a new technology has allowed the trend to continue unabated. For more information see http://www.intel.com/research/silicon/mooreslaw.htm 21-01-2005], and the resultant advances in software and modelling techniques is allowing situations to be modelled in increasing complexity. It also enables designers to have more freedom in what they choose to represent, with fewer of the constraints of primitive computer technology. It is therefore important to understand how this new technology is affecting architectural design today because greater comprehension allows more imaginative use of these technologies.</p>
<p>Technology has always informed architectural design, and large technological advances have inevitably informed changes in architectural styles. Traditionally, from pre-history through to the classical and medieval periods, architecture was one of the major driving forces behind technology because it was a significant part of the war machinery of any state. Fortified towns, castles and other military buildings were as much a part of an arms race[1. Manual de Landa describes the progression of history in European culture as mineralization, whereby towns which would originally have been built and defended with wooden structures became more and more dependant on their architecture as means of defence. Manual De Landa 1000 years of non linear history.] as trebuchets and cannons. As the battles became more high-tech, and the advent of gunpowder made traditional stone fortifications obsolete, other parts of society quickly took over as the driving force behind technological advances. Since then, transport (land, water and air transport) and later information (its collection and dissemination) have been the main impetus behind technological advancement, with other players such as agriculture industry and medicine also contributing, as architecture fell further and further from the cutting edge. Over the last few centuries technologies from other disciplines have cross pollinated into architecture and the prevailing paradigm has changed from one where architecture is a technological innovator to one where architecture is technologically bankrupt, scavenging the innovations that have fallen away from the cutting edge of other industries and trying to integrate them, usually inappropriately, into a ‘style’.</p>
<p>During the last few decades, computers have come to the fore in every field and are utilised in virtually every aspect of modern life, including architecture. However, computing is not just the digital work performed by computers but a general term meaning calculated that can include the complicated analogue calculations found in nature. Calculation is a process that needs to follow a set of rules, but this rule set can be anything from simple arithmetic to the complex non-standard systems found in nature. The arrangement of sand ridges caused by a receding tide on a beach is as much a product of computation as a cad rendering or the output from a spreadsheet.</p>
<p>Analogue calculations have long been used by designers wishing to simulate real world phenomena for example the catenary[1. for a mathematical explanation of catenary curves visit http://mathworld.wolfram.com/Catenary.html] curves to arch force models used by Gaudí to compute the forces in the complex arches and columns in the Sagrada Família. However, it has taken time to bring about a unification between the number crunching abilities of a digital computer and these analogue calculations already involved in architectural design. The first digital computers were invented by Alan Turing[1. Alan Turing ref, probably the Mathland book] to crack the complex enigma code, and early applications were all in the fields of mathematics or engineering because of their huge number crunching abilities in comparison to human mathematicians. Similarly the computer, as applied to architectural design, was to begin with simply a replacement or augmentation of the draughting already undertaken by hand on paper. The computer produced a collection of virtual two dimensional lines on a virtual two dimensional plane, with the express purpose of plotting onto paper using computer controlled mechanical arm with a traditional pen attached to it. It was a device designed specifically to mimic human action, even down to the details of the printing process.</p>
<p>Recently, in a series of evolutionary steps the digital computing process has gained considerable complexity through integration with technologies from other disciplines (engineering analysis, cinema special effects, physics simulation). The original two dimensional virtual space became three dimensional virtual space, and has now become<br />
n-dimensional virtual space, and the crude two dimensional plotting <p>The exponentially increasing processing speed of computers[^1], and the resultant advances in software and modelling techniques is allowing situations to be modelled in increasing complexity. It also enables designers to have more freedom in what they choose to represent, with fewer of the constraints of primitive computer technology. It is therefore important to understand how this new technology is affecting architectural design today because greater comprehension allows more imaginative use of these technologies.</p>
<p>Technology has always informed architectural design, and large technological advances have inevitably informed changes in architectural styles. Traditionally, from pre-history through to the classical and medieval periods, architecture was one of the major driving forces behind technology because it was a significant part of the war machinery of any state. Fortified towns, castles and other military buildings were as much a part of an arms race[^2] as trebuchets and cannons. As the battles became more high-tech, and the advent of gunpowder made traditional stone fortifications obsolete, other parts of society quickly took over as the driving force behind technological advances. Since then, transport (land, water and air transport) and later information (its collection and dissemination) have been the main impetus behind technological advancement, with other players such as agriculture industry and medicine also contributing, as architecture fell further and further from the cutting edge. Over the last few centuries technologies from other disciplines have cross pollinated into architecture and the prevailing paradigm has changed from one where architecture is a technological innovator to one where architecture is technologically bankrupt, scavenging the innovations that have fallen away from the cutting edge of other industries and trying to integrate them, usually inappropriately, into a ‘style’.</p>
<p>During the last few decades, computers have come to the fore in every field and are utilised in virtually every aspect of modern life, including architecture. However, computing is not just the digital work performed by computers but a general term meaning calculated that can include the complicated analogue calculations found in nature. Calculation is a process that needs to follow a set of rules, but this rule set can be anything from simple arithmetic to the complex non-standard systems found in nature. The arrangement of sand ridges caused by a receding tide on a beach is as much a product of computation as a cad rendering or the output from a spreadsheet.</p>
<p>Analogue calculations have long been used by designers wishing to simulate real world phenomena for example the catenary[^3] curves to arch force models used by Gaudí to compute the forces in the complex arches and columns in the Sagrada Família. However, it has taken time to bring about a unification between the number crunching abilities of a digital computer and these analogue calculations already involved in architectural design. The first digital computers were invented by Alan Turing[1. Alan Turing ref, probably the Mathland book] to crack the complex enigma code, and early applic[^4]engineering because of their huge number crunching abilities in comparison to human mathematicians. Similarly the computer, as applied to architectural design, was to begin with simply a replacement or augmentation of the draughting already undertaken by hand on paper. The computer produced a collection of virtual two dimensional lines on a virtual two dimensional plane, with the express purpose of plotting onto paper using computer controlled mechanical arm with a traditional pen attached to it. It was a device designed specifically to mimic human action, even down to the details of the printing process.</p>
<p>Recently, in a series of evolutionary steps the digital computing process has gained considerable complexity through integration with technologies from other disciplines (engineering analysis, cinema special effects, physics simulation).t the extent to which the others impact on performance. Parametric design then becomes very interesting. J Parish from Arup sport is planning to design a parametric design algorithm that will allow him to design an entire sports stadium in a day with all the considerations, from servicing to sight lines covered. The interesting thing is that the program won’t just design one stadium, but the ideal stadium given all the input considerations.</p>
<p>The question at this point in architectural history is one of uptake. Will the design community at large grasp the possibilities offered to make designs fitted exactly to the site, user and program, or will they be transfixed by the cheerful shapes and not look beyond and see the possibilities?</p>
<p>There are a number architects who have made significant contributions to architectural design in this field. This text seeks to explore advances in the field through the study of a number of prominent practitioners and the ways in which they have employed computer technology in the inception of their designs.</p>
<p><img class="alignnone size-full wp-image-1951" src="{{ site.baseurl }}/assets/buttercup1.png" alt="buttercup1" /></p>
<h1 id="frank">Frank Gehry</h1>
<p>Frank Gehry was the first architect to utilise the processing power of computers in the production of built architecture. The resultant constructions have inspired the recent generation of architects to look beyond the familiar rectilinear and experiment with unconventional forms.</p>
<p>The iconic building is the Gehry trademark. Buildings like the Disney music hall in Los Angeles, the Bilbao Guggenheim museum and the bridge Gehry has contributed to Millennium Square in Chicago are all icons in their own right, a city accessory, and an extension of the Gehry brand. In the same way the latest handbag is an indicator of the wearer’s wealth, good taste and willingness to invest in the best for themselves, a Gehry building gives the same kudos to a city, and in an attempt to boost the cities image and media exposure and therefore tourism and economy many are commissioning their own icons. Several large cities have hoped to boost their economies using the so called ‘Bilbao effect’ to promote archi-tourism, and to give their city a presence in the world’s media. For instance Toronto has directly attributed a 2.3% rise in tourism to the new Will Alsop Sharp Centre for Design[1. Sunday times culture magazine 9-1-2005 page 19 Hugh Pearman Alsop’s fabled buildings]. The Gehry brand uses large curving shapes and shiny metal skins, to create buildings more akin to giant sculptures or pseudo futuristic space stations than conventional buildings. The futuristic forms imply a futuristic design method. However for the most part computer technologies actually play only a small part in the design of these buildings and are only really brought into play once a physical model is built that the designers are happy with. As such the computer becomes more of a realisation tool than a design tool. The computer has little or no input into the design of the form[1. computers in design quote and ref].</p>
<p>The current signature Gehry style had its inception with the fish sculpture on the Barcelona seafront commissioned for the 1992 Olympics. The design process involved in the sculptural composition of the fish sculpture began with the design and construction of a physical model using the traditional architectural techniques of paper modelling, a simple sheet of paper was bent and pushed until a desirable form was acquired. No computers were used at this stage. The initial model was scanned using a touch probe scanner, and then recreated in digital space using <span class="small-caps">catia</span> to allow it to be cut up and made into component drawings. At the time this was revolutionary, and the use of computers to create non standard forms seemed very exciting. In an interview with Dassault Systemes, Gehry’s chief partner Jim Glymph said: “The use of <span class="small-caps">catia</span> on our projects has extended the possibilities in design far beyond what we believed was possible ten years ago. We hope that within the next ten years this technology will be available for all architects and engineers,”[1. http://www.3ds.com/news-events/press-room/release/368/1/?encryptionKey=&amp;cHash=f81892a030 12-01-2004]</p>
<p>[caption id="attachment_1953" align="alignnone" width="1000"]<img class="wp-image-1953 size-full" src="{{ site.baseurl }}/assets/bilgug.png" alt="bilgug" width="1000" height="985" /> Guggenheim Museum Bilbao[/caption]</p>
<p>However what Gehry’s computers produce, in essence, isn’t anything new. They merely facilitate the expansion and extension of an existing process making the extended version financially viable by speeding it up. By using a computer to scan a shape that had already been designed and physically modelled, the complex drawings and calculations could be automated whereas the calculations and accuracy of specification for the metal work contractor would have proved too complicated and time consuming to be done manually, given it’s size and latticed copper construction. In essence the use of computers in the design of the sculpture was one borne out of necessity because the calculations and subsequent drawings and specifications necessary to make and support a physically viable structure, without the use of the vast number crunching ability available in a computer was hugely time consuming and not possible to acceptable levels of accuracy. Once programmed with sufficient physics information a computer is a far more reliable engineer than a human because they can employ finite element analysis and other necessary calculations far more rigorously and the drawings produced by computers are more accurate. The real benefit of computer draughting is where there are no drawings at all produced and the computer communicates directly with the manufacturing device (be that a multi axis mill, a laser cutter or a rapid prototyping machine). <span class="small-caps">catia</span> is a particularly powerful program that can do this, borrowed from the aeronautical industry where it is used to design fighter jets. It has a vast range of plug-in accessory modules that allow it to be tailored to one’s needs.8 Gehry uses <span class="small-caps">catia</span> to design and specify all the underlying structural componentry required to support the buildings.</p>
<p>Gehry’s computing techniques were ground breaking at the time, and something that had never been done before. They opened up a host of new possibilities in architecture and the possible architectural forms available to architects to use beyond modifications of the traditional cuboidal shape. These possibilities were extremely exciting for the architectural community and allowed architecture to take its place amongst the physical art forms and made buildings as sculpture possible, extending their value beyond that of practical purposes as shelter. Many of Gehry’s subsequent buildings have used the same technique, and as a result look very similar to the Bilbao Guggenheim, for example the Walt Disney Concert Hall and the Experience Music Project . More recent building projects have used the power of <span class="small-caps">catia</span> to a certain extent, but this is generally in automating the insertion of windows or the specification of steelwork. The Der Neue Zollhof office buildings (1999) are a good example of the more recent Gehry work flow. The form was realised as a physical model, scanned, and then the structure was added as an afterthought and the windows were inserted using a <span class="small-caps">catia</span> subroutine that oriented them towards the most pleasing views. The structural data was the outputted to cnc mills that made the polystyrene moulds for the concrete skin and the steel work data outputted to the contractor.</p>
<p><img class="alignnone size-full wp-image-1955" src="{{ site.baseurl }}/assets/Gehry_Building.jpg" alt="DG Bank, Berlin" /></p>
<p><img class=" wp-image-1957 alignleft" src="{{ site.baseurl }}/assets/gehry-catia1.jpg" alt="gehry catia1" width="204" height="514" />The evolution of the Gehry design technique seems to have stopped soon after the introduction of <span class="small-caps">catia</span>, all his subsequent buildings have used the design, model, scan, support technique. However the inherent human aspect involved in the model creation and the non-involvement of the computer in the design process leads to structurally inefficient buildings which require massively more structure than an equivalent rectilinear building. Most famously the Bilbao Guggenheim museum which looks spectacular from outside, and has had an enormous impact on the economy of Bilbao, but inside is a confused mass of steelwork which contorts itself wildly in order to support the museum’s complex shell.</p>
<p>The design process used by the Gehry office is merely the hand draughting and engineering process speeded up by using computers, the structural data which is generated by <span class="small-caps">catia</span> and ansys is not used to modify the form or design, but merely to specify the structure. It is essentially computer aided drawing, as it was at the dawn of Autocad, or even computer aided sculpture, but the computer is, essentially, left out of the design process.</p>
<p>The Gehry style is essentially a computerisation of the ancient technique of doing a scalar transformation of a three dimensional shape such as that used in Renaissance sculpture. Starting with a small object he makes it a big object. The computer is left out of the design procedure completely, and as such following the Gehry method of design, while not a regressive step is certainly not a step forward.</p>
<p><img class="alignnone wp-image-1956" src="{{ site.baseurl }}/assets/ghery-catia.jpg" alt="ghery catia" width="324" height="126" /></p>
<p class="inter-paragraph">Frank Gehry’s passive physical modelling can be seen as an early step towards the integration of physical and digital forms. The physical form allows the designer to see exactly what the end product will bn-dimensional virtual space, and the crude two dimensional plotting t the extent to which the others impact on performance. Parametric design then becomes very interesting. J Parish from Arup sport is planning to design a parametric design algorithm that will allow him to design an entire sports stadium in a day with all the considerations, from servicing to sight lines covered. The interesting thing is that the program won’t just design one stadium, but the ideal stadium given all the input considerations.</p>
<p>The question at this point in architectural history is one of uptake. Will the design community at large grasp the possibilities offered to make designs fitted exactly to the site, user and program, or will they be transfixed by the cheerful shapes and not look beyond and see the possibilities?</p>
<p>There are a number architects who have made significant contributions to architectural design in this field. This text seeks to explore advances in the field through the study of a number of prominent practitioners and the ways in which they have employed computer technology in the inception of their designs.</p>
<p><img class="alignnone size-full wp-image-1951" src="{{ site.baseurl }}/assets/buttercup1.png" alt="buttercup1" /></p>
<h1 id="frank">Frank Gehry</h1>
<p>Frank Gehry was the first architect to utilise the processing power of computers in the production of built architecture. The resultant constructions have inspired the recent generation of architects to look beyond the familiar rectilinear and experiment with unconventional forms.</p>
<p>The iconic building is the Gehry trademark. Buildings like the Disney music hall in Los Angeles, the Bilbao Guggenheim museum and the bridge Gehry has contributed to Millennium Square in Chicago are all icons in their own right, a city accessory, and an extension of the Gehry brand. In the same way the latest handbag is an indicator of the wearer’s wealth, good taste and willingness to invest in the best for themselves, a Gehry building gives the same kudos to a city, and in an attempt to boost the cities image and media exposure and therefore tourism and economy many are commissioning their own icons. Several large cities have hoped to boost their economies using the so called ‘Bilbao effect’ to promote archi-tourism, and to give their city a presence in the world’s media. For instance Toronto has directly attributed a 2.3% rise in tourism to the new Will Alsop Sharp Centre for Design[^5]. The Gehry brand uses large curving shapes and shiny metal skins, to create buildings more akin to giant sculptures or pseudo futuristic space stations than conventional buildings. The futuristic forms imply a futuristic design method. However for the most part computer technologies actually play only a small part in the design of these buildings and are only really brought into play once a physical model is built that the designers are happy with. As such the computer becomes more of a realisation tool than a design tool. The computer has little or no input into the design of the form[1. computers in design quote and ref].</p>
[^6]<p>The current signature Gehry style had its inception with the fish sculpture on the Barcelona seafront commissioned for the 1992 Olympics. The design process involved in the sculptural composition of the fish sculpture began with the design and construction of a physical model using the traditional architectural techniques of paper modelling, a simple sheet of paper was bent and pushed until a desirable form was acquired. No computers were used at this stage. The initial model was scanned using a touch probe scanner, and then recreated in digital space using <span class="small-caps">catia</span> to allow it to be cut up and made into component drawings. At the time this was revolutionary, and the use of computers to create non standard forms seemed very exciting. In an interview with Dassault Systemes, Gehry’s chief partner Jim Glymph said: “The use of <span class="small-caps">catia</span> on our projects has extended the possibilities in design far beyond what we believed was possible ten years ago. We hope that within the next ten years this technology will be available for all architects and engineers,”[^7]</p>
<p>[caption id="attachment_1953" align="alignnone" width="1000"]<img class="wp-image-1953 size-full" src="{{ site.baseurl }}/assets/bilgug.png" alt="bilgug" width="1000" height="985" /> Guggenheim Museum Bilbao[/caption]</p>
<p>However what Gehry’s computers produce, in essence, isn’t anything new. They merely facilitate the expansion and extension of an existing process making the extended version financially viable by speeding it up. By using a computer to scan a shape that had already been designed and physically modelled, the complex drawings and calculations could be automated whereas the calculations and accuracy of specification for the metal work contractor would have proved too complicated and time consuming to be done manually, given it’s size and latticed copper construction. In essence the use of computers in the design of the sculpture was one borne out of necessity because the calculations and subsequent drawings and specifications necessary to make and support a physically viable structure, without the use of the vast number crunching ability available in a computer was hugely time consuming and not possible to acceptable levels of accuracy. Once programmed with sufficient physics information a computer is a far more reliable engineer than a human because they can employ finite element analysis and other necessary calculations far more rigorously and the drawings produced by computers are more accurate. The real benefit of computer draughting is where there are no drawings at all produced and the computer communicates directly with the manufacturing device (be that a multi axis mill, a laser cutter or a rapid prototyping machine). <span class="small-caps">catia</span> is a particularly powerful program that can do this, borrowed from the aeronautical industry where it is used to design fighter jets. It has a vast ra class="small-caps">nox</span> book] meaning that the nature of the material will affect it’s behaviour in the analogue calculating machine, so the decision to use 80gsm or 120gsm paper, or pvc, leather or wool threads in the design of the machine is important. Equally, the finished product will also be ‘material’ so the inferences drawn from structure can directly related.</p>
<p>The D Tower in Doetinchem in the Netherlands (1998-2004) was designed using a combination process. The top was designed by deforming a sphere in an animation using an algorithm, and “At the point where the sphere, which starts out convex only, seems to have as much concave geometry as convex, [they] suspend the animation.”[1. 160 <span class="small-caps">nox</span> book] Once the top section was fixed a shopping bag analogy was used to design the legs. A mesh shopping bag reconfigures it’s arrangement depending on what is being carried at the time, the top of the D Tower was conceptualized as the shopping and the bag becomes the legs. This was inspired by the idea of using hanging chains to design parabolic arches and force diagrams, originally used by the Romans to design bridges and most famously by Gaudí to design the Sagrada Família. Traditionally floor planes are fixed horizontally, the model inverted, and strain gauges in static cords used to measure the tension and determine the diameter of each leg. However the top section of the D Tower is not inhabited so it’s orientation is unimportant, instead the legs diameters were fixed by using an elastic cord, and the top allowed to rotate to accommodate the forces. This is a simple but effective application of analogue computing.</p>
<p>[caption id="attachment_1962" align="alignnone" width="1000"]<img class="wp-image-1962 size-full" src="{{ site.baseurl }}/assets/dtower-hang.jpg" alt="dtower hang" width="1000" height="650" /> <span class="small-caps">nox</span> Shopping Bag Analogy For The D Tower[/caption]</p>
<p>As many of their projects have complex double curved forms, the methods used to cover them become more problematic. For Blowout (a public toilet in Neeltje Jans in the Netherlands, 1997) the skin was simply covered in mesh and sprayed with concrete, creating a homogenous surface. The more recent Son-O-House[1. a house where sounds live. Public art work for industrieschap Ekkersrijt, in collaboration with composer Edwin van der Heide, Son en Breugel, the Netherlands 2000-04. ] has a much more complicated skin of expanded mesh that is applied according to a set of rules given to the contractor. The rules govern the positioning and tessellation of a series of panels and the resulting surface has a pattern produced by the orientation of the cuts that produce the mesh and the resulting moiré effect is very interesting.</p>
<p>[caption id="attachment_1980" align="alignnone" width="1000"]<img class="wp-image-1980 size-full" src="{{ site.baseurl }}/assets/meet-strips.jpg" alt="meet strips" width="1000" height="349" /> A rule defines the pattern that covers the surface of the Sonohouse, regular surfaces (above) give regular tessalation, wheras irregular surfaces (right) give broken tessellation.[/caption]</p>
<p>The <span class="small-caps">nox</span> approach embraces indeterminacy, their Iterative computational experiments yield unpredictable results and are pushing <span class="small-caps">nox</span> on to produce more and more innovative designs. The use of computers is very much evolutionary because even though they are repeating many of the experiments performed by Frei Otto, they are applying the computer in a way which takes them out of the realm of playful experiments and places them firmly into that of useful architectural tools. These approaches allow <span class="small-caps">nox</span> to control the overall design process, but the points at which they let go and allow the machines to take over creates unexpected and elegant solutions.</p>
<p>[caption id="attachment_1963" align="alignnone" width="1000"]<img class="wp-image-1963 size-full" src="{{ site.baseurl }}/assets/sono-r.jpg" alt="sono r" width="1000" height="568" /> <span class="small-caps">nox</span> Son-O-House [1. p343 nox book][/caption]<img class="alignnone size-full wp-image-1964" src="{{ site.baseurl }}/assets/36-caribou.jpg" alt="36-caribou" /></p>
<p class="inter-paragraph">The complexity involved in the final form of something like a wool thread model can usually be reduced to a surprisingly simple set of rules. The study of complexity generated from simple systems becomes very interesting, positive or negative feedback can send a system off into total chaos, or keep it from really doing anything. These mathematical concepts can be applied to natural phenomena such as the wax and wane of caribou populations[1. pi film] or the arrangement of seeds in a sunflower head.</p>
<p class="inter-paragraph">So if nature holds such fascinating structural mathematics then what happens if we abstract those rules and apply them to architecture? This is exactly what the Emergence and Design Group have done.</p>
<h1 id="emergence">[Emergence and Design Group] Micheal Hensel, Mike Weinstock, Achim Menges</h1>
<p>In 1917 D’arcy Thompson published a book called ‘On Growth and Form’ which studies the structure of complex single cell organisms[1. p365 nox book]. This, in part led to bioconstructivism, which looks at the ways in which nature has organised itself, such as the tessellation of pine cone ‘scales’ based on opposing helixes, and the ways in which broccoli florets arrange themselves according to the Fibonacci sequence. Emergence is a rigorous application of mathematics to these findings from nature, and a subsequent reapplication of those principles to other aspects of life, such as the development of artificial intelligence, or predicting stock market fluctuations. Until recently the term ‘emergence’ was generally used as a buzzword in architectural circles to refer to any seemingly complex system. Recently however, it has been steered onto the more stringent definition as “a system that cannot be deduced from its parts”[1. p5 ad].</p>
<p>The most commonly cited example of the application of emergent design to architecture is termite mounds. Termite mounds have a complex system of tunnels that the termites use for their daily lives, but they are also used by the termites to carefully regulate the temperature of the whole mound by blocking and unblocking external openings, depending on the prevailing winds and the internal ambient temperature. There is no central control from the queen, and the termites themselves have no concept of the global situation, but as the termites are essentially identical, if one of them gets cold then it simply blocks up the nearest hole, and then unblocks it when it gets too warm. As the termites work to a very simple set of rules, and each of them has the same programming, the system runs efficiently.</p>
<p>Termites use an even simpler set of rules when building the mound in the first place.</p>
<pre>Whilst wandering randomly
  If you find something
    then pick it up
      unless you’re already carrying something
        in which case drop it
</pre>
<p>They change the environment and the changed environment modifies their behavior[1. http://www.beart.org.uk/Emergent/ 11-01-2005].</p>
<p>A termite finds a piece of wood and then caries it around until he finds another piece of wood, then he drops the piece and continues wandering around until he finds a third one and he repeats the process. As time passes many small mounds are produced which develop into fewer and fewer larger mounds until one mound will grow more than others. The larger mounds have a proportionally smaller surface area to volume ratios compared to the smaller mounds. Therefore, in the larger mounds, a greater proportion of the mound’s pieces are ‘protected’ from collection by being in the interior. As a result the larger mounds tend to grow and the smaller mounds to shrink until only one is left.</p>
<table>
<tbody>
<tr>
<td><img class="alignnone size-full wp-image-1966" src="{{ site.baseurl }}/assets/termite.jpg" alt="termite" /></td>
<td>
<p>[caption id="attachment_1965" align="alignnone" width="650"]<img class="wp-image-1965 size-full" src="{{ site.baseurl }}/assets/termite-cut.jpg" alt="termite cut" width="650" height="694" /> Termite Nest[/caption]</td>
</tr>
</tbody>
</table>
<p>Emergent systems tend to be very complex, but the complexity is created by a large number of iterations of a very simple set of rules. The Spirograph sets that children use are a very simple example of this. The rules involved in the creation of the pattern are very simple, but the actual pattern created is much more complex.</p>
<p>[caption id="attachment_1968" align="alignnone" width="1000"]<a href="/wordpress/wp-content/uploads/2015/10/genr8.jpg" rel="attachment wp-att-1968"><img class="wp-image-1968 size-full" src="{{ site.baseurl }}/assets/genr8.jpg" alt="genr8" width="1000" height="1254" /></a> Form Designed Using Genr8[/caption]</p>
<p><img class="alignleft wp-image-1944" src="{{ site.baseurl }}/assets/darchy-1.jpg" alt="darchy 1" width="303" height="1014" />The Emergence and Design Group is attached to the Emergent Technologies and Design masters program at the Architectural Association in London, and their work is essentially research based, trying to “produce a new research-based model of architectural enquiry”[1. p5 AD on emergence], rather than the formal, or concept led design methods of recent years.</p>
<p>The Emergence and Design Group look to nature to find their rule sets. Evolution has had millennia of gradually evolving structural precedents, and due to the autonomous way in which cells function these natural structures grow according to very simple rules. For example plants lean towards the sun, thereby maximising the area of their leaves exposed for photosynthesis. They do this without any central processing unit, simply by using the turgescence of certain cells that are activated by the exposure, or lack thereof, to light[1. http://www.biologie.uni-hamburg.de/b-online/e32/32d.htm 12-01-04]. If these gr<p class="inter-paragraph">Frank Gehry’s passive physical modelling can be seen as an early step towards the integration of physical and digital forms. The physical form allows the designer to see exactly what the end product will b class="small-caps">nox</span> book] meaning that the nature of the material will affect it’s behaviour in the analogue calculating machine, so the decision to use 80gsm or 120gsm paper, or pvc, leather or wool threads in the design of the machine is important. Equally, the finished product will also be ‘material’ so the inferences drawn from structure can directly related.</p>
<p>The D Tower in Doetinchem in the Netherlands (1998-2004) was designed using a combination process. The top was designed by deforming a sphere in an animation using an algorithm, and “At the point where the sphere, which starts out convex only, seems to have as much concave geometry as convex, [they] suspend the animation.”[^8] Once the top section was fixed a shopping bag analogy was used to design the legs. A mesh shopping bag reconfigures it’s arrangement depending on what is being carried at the time, the top of the D Tower was conceptualized as the shopping and the bag becomes the legs. This was inspired by the idea of using hanging chains to design parabolic arches and force diagrams, originally used by the Romans to design bridges and most famously by Gaudí to design the Sagrada Família. Traditionally floor planes are fixed horizontally, the model inverted, and strain gauges in static cords used to measure the tension and determine the diameter of each leg. However the top section of the D Tower is not inhabited so it’s orientation is unimportant, instead the legs diameters were fixed by using an elastic cord, and the top allowed to rotate to accommodate the forces. This is a simple but effective application of analogue computing.</p>
<p>[caption id="attachment_1962" align="alignnone" width="1000"]<img class="wp-image-1962 size-full" src="{{ site.baseurl }}/assets/dtower-hang.jpg" alt="dtower hang" width="1000" height="650" /> <span class="small-caps">nox</span> Shopping Bag Analogy For The D Tower[/caption]</p>
<p>As many of their projects have complex double curved forms, the methods used to cover them become more problematic. For Blowout (a public toilet in Neeltje Jans in the Netherlands, 1997) the skin was simply covered in mesh and sprayed with concrete, creating a homogenous surface. The more recent Son-O-House[^9] has a much more complicated skin of expanded mesh that is applied according to a set of rules given to the contractor. The rules govern the positioning and tessellation of a series of panels and the resulting surface has a pattern produced by the orientation of the cuts that produce the mesh and the resulting moiré effect is very interesting.</p>
<p>[caption id="attachment_1980" align="alignnone" width="1000"]<img class="wp-image-1980 size-full" src="{{ site.baseurl }}/assets/meet-strips.jpg" alt="meet strips" width="1000" height="349" /> A rule defines the pattern that covers the surface of the Sonohouse, regular surfaces (above) give regular tessalation, wheras irregular surfaces (right) give broken tessellation.[/caption]</p>
<p>The <span class="small-caps">nox</span> approach embraces indeterminacy, their Iterative computational experiments yield unpredictable results and are pushing <span class="small-caps">nox</span> on to produce more and more innovative designs. The use of computers is very much evolutionary because even though they are repeating many of the experiments performed by Frei Otto, they are applying the computer in a way which takes them out of the realm of playful experiments and places them firmly into that of useful architectural tools. These approaches allow <span class="small-caps">nox</span> to control the overall design process, but the points at which they let go and allow the machines to take over creates unexpected and elegant solutions.</p>
<p>[caption id="attachment_1963" align="alignnone" width="1000"]<img class="wp-image-1963 size-full" src="{{ site.baseurl }}/assets/sono-r.jpg" alt="sono r" width="1000" height="568" /> <span class="small-caps">nox</span> Son-O-House [^10][/caption]<img class="alignnone size-full wp-image-1964" src="{{ site.baseurl }}/assets/36-caribou.jpg" alt="36-caribou" /></p>
<p class="inter-paragraph">The complexity involved in the final form of something like a wool thread model can usually be reduced to a surprisingly simple set of rules. The study of complexity generated from simple systems becomes very interesting, positive or negative feedback can send a system off into total chaos, or keep it from really doing anything. These mathematical concepts can be applied to natural phenomena such as the wax and wane of caribou populations[^11] or the arrangement of seeds in a sunflower head.</p>
<p class="inter-paragraph">So if nature holds such fascinating structural mathematics then what happens if we abstract those rules and apply them to architecture? This is exactly what the Emergence and Design Group have done.</p>
<h1 id="emergence">[Emergence and Design Group] Micheal Hensel, Mike Weinstock, Achim Menges</h1>
<p>In 1917 D’arcy Thompson published a book called ‘On Growth and Form’ which studies the structure of complex single cell organisms[^12]. This, in part led to bioconstructivism, which looks at the ways in which nature has organised itself, such as the tessellation of pine cone ‘scales’ based on opposing helixes, and the ways in which broccoli florets arrange themselves according to the Fibonacci sequence. Emergence is a rigorous application of mathematics to these findings from nature, and a subsequent reapplication of those principles to other aspects of life, such as the development of artificial intelligence, or predicting stock market fluctuations. Until recently the term ‘emergence’ was generally used as a buzzword in architectural circles to refer to any seemingly complex system. Recently however, it has been steered onto the more stringent definition as “a system that cannot be deduced from itd automation allowed Foster &amp; Partners to produce a virtually finished competition entry on a very quick time scale. Once the concept had been formulated gc was used to design the actual form and the construction detailing. The program allowed the designers to pull the design around as if it was a malleable physical model using it’s parameters giving a much greater degree of design resolution than would otherwise be possible.</p>
<p>The group has been running a number of seminars and workshops over the last 2 years to introduce some of the industries top designers and also some students to the possibilities offered by the beta version of gc. They assert that, with gc one is modelling a set of relationships between points, lines and planes rather than geometry, and the geometry is almost incidental. Ironically mathematicians in some fields see this as quite an accurate definition of geometry.</p>
<table>
<tbody>
<tr>
<td><img class="alignnone size-full wp-image-1977" src="{{ site.baseurl }}/assets/Kimpian032.jpg" alt="Kimpian03[2]" /></td>
<td><img class="alignnone size-medium wp-image-1976" src="{{ site.baseurl }}/assets/Kimpian021.jpg" alt="Kimpian02[1]" /></td>
<td><img class="alignnone size-full wp-image-1975" src="{{ site.baseurl }}/assets/Kimpian011.jpg" alt="Kimpian01[1]" /></td>
</tr>
</tbody>
</table>
<p>The methods of producing architectural design researched by the Smart Geometry Group are not only allowing for the automation of the menial and time consuming, but also for the design to work in tandem with the structure. This thereby brings the architect and the engineer back into dialogue throughout the process and allows designs to become more innovative and interesting with elegance an inherent part of their design, rather than creating a battle between architect and engineer to get the desired result.</p>
<p>The Smart Geometry Group’s use of parametric algorithms to enable and accelerate design is probably the theoretical research most likely to become mainstream. Within the next ten years the concept of architect as tool builder will become a reality simply because of commercial pressures. Their techniques can allow designers to produce mediocre designs quickly by using ready made tools. However the true future of the software will be in the opportunities for using the tool building process as a design task in itself.</p>
<p>[caption id="attachment_1978" align="alignnone" width="1000"]<img class="wp-image-1978 size-full" src="{{ site.baseurl }}/assets/CWSculptureOpt1.jpg" alt="CWSculptureOpt[1]" width="1000" height="380" /> Parametric Study For a Sculpture - Dr Chris Williams[/caption]&nbsp;</p>
<p class="inter-paragraph">The most significant creation of the information revolution has been the birth of the internet. As modern life becomes increasingly dependant on the interactive interfaces, and the vast wealth of the information stored within, the way that we interact with computers becomes a concern. Do we look at them or do we inhabit them?</p>
<h1 id="novak">Marcus Novak</h1>
<p>Novak has been involved in researching and conceptualising the use of computers in architecture since the late seventies. He has held various positions at American universities researching the architectural implications of digital technologies, and has been at the forefront of the research into virtually all the computer technologies that are applicable to architecture today.</p>
<p>Imbued with a classical Greek education Novak was fascinated from an early age with geometry, music, art, logic etc. He eventually settled on becoming an architect and struggled to reconcile his interests with his chosen profession, urged by many to discard some of them to focus on others. Refusing to do so he attempted to make an architecture that encompassed them all.</p>
<p>As much of Novak’s work is purely research based it allows itself to push the boundaries of what is considered architecture into art, computer graphics and mathematics. He stresses the importance of being “intellectually multilingual”[1. blob page 219], as are an increasing number of architects who are pushing the boundaries of what the computer makes possible. The ability to speak the languages of other disciplines is allowing the conceptual and technical advancement of those disciplines to enrich architecture.</p>
<p>Generative composition has been an accepted practice for a long time in music and Brian Eno’s Koan[1. For more information on Koan visit http://www.sseyo.com/products/koanpro/index.html] project was the first to bring it to the mass stage. Novak took these algorithms that generated musical compositions and modified them to work on spatial dimensions. His theory of ‘liquid architecture’ is based on the way music is formalised. The parametric nature of the classical orders inspired a way of thinking about architecture as a set of parameters that was lost on most people at the time, but has come to be one of the most important concepts in modern computerised architectural design. He attempted to create computer code that would recognise beauty, long considered a dirty word in intellectual circles due to the illusive nature of a rigorous definition. He used an amalgamation of several previous methods taken from different fields[1. in Blobmeister (full ref page 227) he cites Dawkins (an evolutionary biologist who theorises that evolution has no direction, but rather it exploits opportunities as they arise and the organisms fitness is relevant to it’s time), Shannon’s information theory (a way of measuring the volume of data that can be passed through a given channel) and Pareto optimality (a theory that allows a group of individuals to coexist by making decisions that will be benificial to the group ratehr than directy to that individual)] to grow and breed designs based on his fitness criteria of beauty. The resultant forms were indeed beautiful and elegant, but did contain objects floating in space and other such unbuildable forms.</p>
<p>Through his teaching and research, Novak discovered that the early tools designed for a generic designer were inappropriate for most applications because most designers were working in non-generic situations. He started making his own tools and integrating computers into his teaching at Ohio State University five years before Bernard Tschumi set up the ‘paperless studio’ at Columbia. His theory was that if architectural form could be freed from the economic restraints that it is currently tied with by using these ‘tools’ then form would become regulated by human preference.</p>
<p>[caption id="attachment_1983" align="alignnone" width="1000"]<img class="wp-image-1983 size-full" src="{{ site.baseurl }}/assets/allobio_ortho2-axo11.jpg" alt="allobio_ortho2-axo1[1]" width="1000" height="795" /> Alien Bio[/caption]He created one of the first virtual reality environments outside military usage with ‘Dancing with the Virtual Dervish’ finally achieved the immersion required to really inhabit virtual space. The individual optical inputs simulated binocular vision and the head movement based navigation system removed the degree of dislocation associated with the ability to look beyond the two dimensional screen and from using hands to move the field of vision. This was the first significant foray into inhabiting cyberspace in an architectural manner, and although most of the environments conceived were ‘unbuildable’ in the physical world it set a precedent for other architects to follow.</p>
<p><img class="alignnone size-full wp-image-1998" src="{{ site.baseurl }}/assets/v4Dxyz_Visio_1024x3421.png" alt="v4Dxyz_Visio_1024x342[1]" /></p>
<p>With the constraints of having to design for the physical world essentially removed, Novak experimented with complex geometrical concepts in the virtual world. The first obstacle to transcend was the obvious barrier of multidimensional space, his complex parametric four dimensional designs yielded hyper-surfaces as the resultant three dimensional form. This allowed him to create architecture that doesn’t conform to our conventional Euclidean view of the world.</p>
<p><img class="alignnone size-full wp-image-1999" src="{{ site.baseurl }}/assets/d2a_echino_rp_252.png" alt="d2a_echino_rp_25[2]" /></p>
<p class="inter-paragraph">Novak’s work continues to explore the boundaries of what digital technologies make possible, the inhabitation of virtual space is now a significant issue in architectural discourse. Most of Novak’s work is highly conceptual, and beyond the understanding of the general populous.</p>
<p class="inter-paragraph">Asymptote, however are creating virtual spaces that blur the boundaries between the real and virtual worlds.</p>
<h1 id="asymptote">Asymptote - Hani Rashid &amp; Lise Anne Couture</h1>
<p>Asymptote are involved in exploring the boundary between real and virtual space, their work either straddles this boundary, or remains entirely in the virtual domain. Hani Rashid and Lise Anne Couture have been pushing the boundaries of what can conventionally be called architecture for the last nine years. They courted major media controversy for their New York Stock Exchange Virtual Trading Floor (nyse 3dtf). The nyse 3dtf was a virtual environment for trading stocks, but the question of whether or not a space created inside a computer, that cannot be physically inhabited, could be deemed architecture whilst still inside the intangible realm of virtual space was fiercely contested.</p>
<p>[caption id="attachment_2000" align="alignnone" width="1000"]<img class="wp-image-2000 size-full" src="{{ site.baseurl }}/assets/iscape.png" alt="iscape" width="1000" height="716" /> i:scapes Venice Bienale 2000[/caption]</p>
<p>Ever since William Gibson invented cyberspace in his 1984 book Neuromancer[1. Neuromancer was responsible for nearly all of the current sci-fi concepts that we are all familiar with today, terms such as the matrix and cyberspace. “Cyberspace...a graphic representation of data abstracted from the banks of every computer in the human system. Unthinkable complexity. Lines of light ranged in the nonspace of the mind, clusters and constellations of data. Like city ligh<p>The Emergence and Design Group look to nature to find their rule sets. Evolution has had millennia of gradually evolving structural precedents, and due to the autonomous way in which cells function these natural structures grow according to very simple rules. For example plants lean towards the sun, thereby maximising the area of their leaves exposed for photosynthesis. They do this without any central processing unit, simply by using the turgescence of certain cells that are activated by the exposure, or lack thereof, to light[^16]. If these grd automation allowed Foster &amp; Partners to produce a virtually finished competition entry on a very quick time scale. Once the concept had been formulated gc was used to design the actual form and the construction detailing. The program allowed the designers to pull the design around as if it was a malleable physical model using it’s parameters giving a much greater degree of design resolution than would otherwise be possible.</p>
<p>The group has been running a number of seminars and workshops over the last 2 years to introduce some of the industries top designers and also some students to the possibilities offered by the beta version of gc. They assert that, with gc one is modelling a set of relationships between points, lines and planes rather than geometry, and the geometry is almost incidental. Ironically mathematicians in some fields see this as quite an accurate definition of geometry.</p>
<table>
<tbody>
<tr>
<td><img class="alignnone size-full wp-image-1977" src="{{ site.baseurl }}/assets/Kimpian032.jpg" alt="Kimpian03[2]" /></td>
<td><img class="alignnone size-medium wp-image-1976" src="{{ site.baseurl }}/assets/Kimpian021.jpg" alt="Kimpian02[1]" /></td>
<td><img class="alignnone size-full wp-image-1975" src="{{ site.baseurl }}/assets/Kimpian011.jpg" alt="Kimpian01[1]" /></td>
</tr>
</tbody>
</table>
<p>The methods of producing architectural design researched by the Smart Geometry Group are not only allowing for the automation of the menial and time consuming, but also for the design to work in tandem with the structure. This thereby brings the architect and the engineer back into dialogue throughout the process and allows designs to become more innovative and interesting with elegance an inherent part of their design, rather than creating a battle between architect and engineer to get the desired result.</p>
<p>The Smart Geometry Group’s use of parametric algorithms to enable and accelerate design is probably the theoretical research most likely to become mainstream. Within the next ten years the concept of architect as tool builder will become a reality simply because of commercial pressures. Their techniques can allow designers to produce mediocre designs quickly by using ready made tools. However the true future of the software will be in the opportunities for using the tool building process as a design task in itself.</p>
<p>[caption id="attachment_1978" align="alignnone" width="1000"]<img class="wp-image-1978 size-full" src="{{ site.baseurl }}/assets/CWSculptureOpt1.jpg" alt="CWSculptureOpt[1]" width="1000" height="380" /> Parametric Study For a Sculpture - Dr Chris Williams[/caption]&nbsp;</p>
<p class="inter-paragraph">The most significant creation of the information revolution has been the birth of the internet. As modern life becomes increasingly dependant on the interactive interfaces, and the vast wealth of the information stored within, the way that we interact with computers becomes a concern. Do we look at them or do we inhabit them?</p>
<h1 id="novak">Marcus Novak</h1>
<p>Novak has been involved in researching and conceptualising the use of computers in architecture since the late seventies. He has held various positions at American universities researching the architectural implications of digital technologies, and has been at the forefront of the research into virtually all the computer technologies that are applicable to architecture today.</p>
<p>Imbued with a classical Greek education Novak was fascinated from an early age with geometry, music, art, logic etc. He eventually settled on becoming an architect and struggled to reconcile his interests with his chosen profession, urged by many to discard some of them to focus on others. Refusing to do so he attempted to make an architecture that encompassed them all.</p>
<p>As much of Novak’s work is purely research based it allows itself to push the boundaries of what is considered architecture into art, computer graphics and mathematics. He stresses the importance of being “intellectually multilingual”[^17], as are an increasing number of architects who are pushing the boundaries of what the computer makes possible. The ability to speak the languages of other disciplines is allowing the conceptual and technical advancement of those disciplines to enrich architecture.</p>
<p>Generative composition has been an accepted practice for a long time in music and Brian Eno’s Koan[^18] project was the first to bring it to the mass stage. Novak took these algorithms that generated musical compositions and modified them to work on spatial dimensions. His theory of ‘liquid architecture’ is based on the way music is formalised. The parametric nature of the classical orders inspired a way of thinking about architecture as a set of parameters that was lost on most people at the time, but has come to be one of the most important concepts in modern computerised architectural design. He attempted to create computer code that would recognise beauty, long considered a dirty word in intellectual circles due to the illusive nature of a rigorous definition. He used an amalgamation of several previous methods taken from different fields[1. in Blobmeister (full ref page 227) he cites Dawkins (an evolutionary biologist [^19]orms were indeed beautiful and elegant, but did contain objects floating in space and other such unbuildable forms.</p>
<p>Through his teaching and research, Novak discovered that the early tools designed for a generic designer were inappropriate for most applications because most designers were ork overlaps in it’s research methods, both Rashid and Lynn teach in order to force the intellectual side of their work along much faster than if they relied on envisioned clients to fund experimentality.</p>
<h1 id="greg">Form - Greg Lynn</h1>
<p>Greg Lynn’s fascination with fabrication seems a little odd when considered in the context of digital design, but it becomes clearer when you consider that he is addressing the opposite side of the equation to most of the other practitioners in the digital realm, and attempting to bring the shapes designed in Maya and 3D studio out of the digital realm and into the physical one.</p>
<p>Nobody has addressed the issue of the creation of digitally designed spaces quite as much as Greg Lynn. The majority of problems faced when translating complex non-standard geometry from a computer into a physical object have already been surmounted by automotive, aeronautical or nautical transport industries. The ability to make any object that one can conceive pushes Lynn to conceive more and more complex shapes as his thought process is not limited by the conventional boundaries of what is possible, and by using the dense network of experimental fabrication facilities in California, Lynn is able to create virtually anything. Nearly all the concept car workshops and most of the Hollywood special effects props industry are based on the west coast.</p>
<p>With Lynn’s architecture taking a step into the world of machine fabrication, the final surface finish comes into question, just as when using an animation technique to find a form one must chose a moment to freeze the frame. The point along the manufacturing process where one decides that the object is finished fascinates Lynn. The intellectual decision of what defines decoration is called into play here; is an articulated artefacted surface more decorated than a smooth polished one if the polishing is an additional step in the objects production, or is decoration an addition process. Lynn explains the concept succinctly in the chapter introduction to “intricate pattern, relief and texture” where he explains how the tool path defined by the computer is created from the 3d data of the computer model, converting a complex surface made up of splines into a series of two dimensional tool sweeps. These tool sweeps leave a pattern on the surface, both from their shape and also the cutting action. A tool will often pass over the same point several times with the cutting path in a different plane to remove extra material, but as the material is removed the moiré interface patterns become a feature of the object. The way the object is produced, and it’s resultant ‘birthmarks’ are as important as the shiny smooth object that we visualise in the computer.</p>
<p>[caption id="attachment_2004" align="alignnone" width="1000"]<img class="wp-image-2004 size-full" src="{{ site.baseurl }}/assets/chess.jpg" alt="chess" width="1000" height="784" /> Chess Board: fabricated using the technology behind concept car headlamps.[/caption]</p>
<p>This unexpected, almost serendipitous result of the machine interface is carried through to other areas of Lynn’s design work. When one offsets a spline in a computer sufficiently, loops begin to appear in places of sufficient initial curvature, in most software these loops are then removed by ‘loop cutting’ algorithms because they are conventionally viewed as a software glitch. Lynn believes that in order to use software to it’s fullest you must understand what it is actually doing, then you can decide if it is working for you or against you. By switching this feature off, he has used the loop creation to design several buildings, including the Eyebeam Atelier Museum of Art and technology (competition entry in New York) and his own home in Venice Beach California. The looped splines are lofted and altered along a path and the intersections produce the defining edges of spaces.</p>
<p>[caption id="attachment_2003" align="alignnone" width="1000"]<img class="wp-image-2003 size-full" src="{{ site.baseurl }}/assets/lynn-surface.jpg" alt="lynn surface" width="1000" height="784" /> Instalation at rendel &amp; spitz : the gap. it experiments with surface finish as a decoration.[/caption]</p>
<p>Lynn also uses algorithms to his advantage. The Kleiberg housing block in Amsterdam (2002) is a refurbishment of an older housing project made in a single building. After careful consideration of the brief, an algorithm was written which subdivided the interior into neighbourhoods accessed by escalators. The escalators were then supported by a ribbed system that also sheltered them. The form of these ribs was defined partially by a kit of parts approach, and partially by an algorithm which interrogated the two ribs preceding it and defined its shape depending on the tension and inertia of the shape as the algorithm was run from left to right, and then from right to left to finally define their shape. This results in the surface of the building having a visually well balanced façade, whose design incorporates structural concerns and also fits the program perfectly</p>
<p>[caption id="attachment_2006" align="alignnone" width="426"]<img class="wp-image-2006 size-full" src="{{ site.baseurl }}/assets/MACHINING-PATTERN.png" alt="MACHINING PATTERN" width="426" height="443" /> The two halves of this test board have the same shape in the computer, but it is interpreted differently by the cnc tool path program producing wildly different results[/caption]</p>
<p>Lynn’s approach of combining the power of software with the intricacies of real world fabrication leads to some fascinating forms. The computer is essential to this all as its own idiosyncrasies as a medium are being explored rather than it being used to simulate a traditional process.</p>
<p>[caption id="attachment_2007" align="alignnone" width="1000"]<img class="wp-image-2007 size-full" src="{{ site.baseurl }}/assets/loop-building.jpg" alt="loop building" width="1000" height="606" /> lynn uses lofts of looped splines to define spaces[/caption]</p>
<hr />
<h1 id="conclusion">Conclusion</h1>
<p>The desire that cities are currently showing to promote archi-tourism only serves to highlight the level of media coverage that unconventional architecture attracts. However the current climate surrounding digital design is notable now not for what the media covers, but for what it ignores. Nobody is writing articles about new buildings being drawn up using AutoCAD LT[1. ref architectural labs conversation in the middle] to produce neat drawings. The use of CAD for the production of drawings is now considered universal, using traditional methods is now deemed, as it is in so many industries, either a rejection of modern methods for a cultural or intellectual reason, or a lack of professionalism in not having the correct tools for the job. In the not too distant future, the use of three dimensional design tools such as Archicad[1. http://www.graphisoft.com/products/archicad/] or Architectural Desktop[1. For more information on Architectural Desktop visit http://www.autodesk.co.uk/adsk/servlet/index?siteID=452932&amp;id=4014829] will be ubiquitous and therefore also deemed unworthy of media attention. One can only hope that eventually the cutting edge tools and methods will loose their newness and be adopted by more conservative practices. The competitive advantage of being able to produce finished designs in a few days by using parametric design programs, as demonstrated by the stadia designed by Arup Sport, will force the industry to pay attention and begin to adopt the methods.</p>
<p>There is a general fear of algorithms amongst architects who’s predominantly ‘artistic’ nature disposes them to be distrustful of technical things, but when one parallels parametric design with the technology of rendering then it becomes less daunting in the long term. Ten years ago rendering was a highly mathematical and very much programming based, requiring an in depth knowledge of the processes involved. These days there is an enormous level of automation already built into the software, making rendering extremely simple. Parametric design is intrinsically more complicated than rendering, as individual rule sets need to be formulated whereas, in rendering, once the way in which light behaves is codified it is just a matter of refining it, but as software advances and more tools are imbedded in the interface, it will become more instinctive. Structures is easily refined back to maths, maths to programming, programming to tools, these tools allow designers to work with the real thing, in real time.</p>
<p>The design possibilities offered by combining digital and analogue computing provide fascinating possibilities for producing beautiful elegant forms. Both specifically designed analogue computing devices (as used by <span class="small-caps">NOX</span>) and the study of biological entities (Emergence and Design Group) give an insight to material performance that was lacking throughout most of the modern movement. The important thing to consider when employing these methods is that in the production of biomimetic designs, the cell or plant structure is essentially diagrammatic and the designer must abstract the structural rule set and apply it in a recontextualised way. We should not be building towers that look like termite mounds or daisies, but rather that we use the structural and organisational techniques intrinsic to their implication.</p>
<p>[caption id="attachment_2008" align="alignnone" width="1000"]<img class="wp-image-2008 size-full" src="{{ site.baseurl }}/assets/CausticsPool.jpg" alt="CausticsPool" width="1000" height="784" /> A rendered scene with animated water that refracts light. ten years ago this would have been unthinkable.[/caption]</p>
<p><img class="wp-image-2010 alignright" src="{{ site.baseurl }}/assets/spaceframe.jpg" alt="spaceframe" width="301" height="177" />Robert Aish of Bentley Systems draws a graph of the idealised design process, a straight line from inception to completion. He then overlays the realistic path taken by a design as its characteristics are modified, advanced, regressed<p>Ever since William Gibson invented cyberspace in his 1984 book Neuromancer[1. Neuromancer was responsible for nearly all of the current sci-fi concepts that we are all familiar with today, terms such as the matrix and cyberspace. “Cyberspace...a graphic representation of data abstracted from the banks of every computer in the human system. Unthinkable complexity. Lines of light ranged in the nonspace of the mind, clusters and constellations of data. Like city lighork overlaps in it’s research methods, both Rashid and Lynn teach in order to force the intellectual side of their work along much faster than if they relied on envisioned clients to fund experimentality.</p>
<h1 id="greg">Form - Greg Lynn</h1>
<p>Greg Lynn’s fascination with fabrication seems a little odd when considered in the context of digital design, but it becomes clearer when you consider that he is addressing the opposite side of the equation to most of the other practitioners in the digital realm, and attempting to bring the shapes designed in Maya and 3D studio out of the digital realm and into the physical one.</p>
<p>Nobody has addressed the issue of the creation of digitally designed spaces quite as much as Greg Lynn. The majority of problems faced when translating complex non-standard geometry from a computer into a physical object have already been surmounted by automotive, aeronautical or nautical transport industries. The ability to make any object that one can conceive pushes Lynn to conceive more and more complex shapes as his thought process is not limited by the conventional boundaries of what is possible, and by using the dense network of experimental fabrication facilities in California, Lynn is able to create virtually anything. Nearly all the concept car workshops and most of the Hollywood special effects props industry are based on the west coast.</p>
<p>With Lynn’s architecture taking a step into the world of machine fabrication, the final surface finish comes into question, just as when using an animation technique to find a form one must chose a moment to freeze the frame. The point along the manufacturing process where one decides that the object is finished fascinates Lynn. The intellectual decision of what defines decoration is called into play here; is an articulated artefacted surface more decorated than a smooth polished one if the polishing is an additional step in the objects production, or is decoration an addition process. Lynn explains the concept succinctly in the chapter introduction to “intricate pattern, relief and texture” where he explains how the tool path defined by the computer is created from the 3d data of the computer model, converting a complex surface made up of splines into a series of two dimensional tool sweeps. These tool sweeps leave a pattern on the surface, both from their shape and also the cutting action. A tool will often pass over the same point several times with the cutting path in a different plane to remove extra material, but as the material is removed the moiré interface patterns become a feature of the object. The way the object is produced, and it’s resultant ‘birthmarks’ are as important as the shiny smooth object that we visualise in the computer.</p>
<p>[caption id="attachment_2004" align="alignnone" width="1000"]<img class="wp-image-2004 size-full" src="{{ site.baseurl }}/assets/chess.jpg" alt="chess" width="1000" height="784" /> Chess Board: fabricated using the technology behind concept car headlamps.[/caption]</p>
<p>This unexpected, almost serendipitous result of the machine interface is carried through to other areas of Lynn’s design work. When one offsets a spline in a computer sufficiently, loops begin to appear in places of sufficient initial curvature, in most software these loops are then removed by ‘loop cutting’ algorithms because they are conventionally viewed as a software glitch. Lynn believes that in order to use software to it’s fullest you must understand what it is actually doing, then you can decide if it is working for you or against you. By switching this feature off, he has used the loop creation to design several buildings, including the Eyebeam Atelier Museum of Art and technology (competition entry in New York) and his own home in Venice Beach California. The looped splines are lofted and altered along a path and the intersections produce the defining edges of spaces.</p>
<p>[caption id="attachment_2003" align="alignnone" width="1000"]<img class="wp-image-2003 size-full" src="{{ site.baseurl }}/assets/lynn-surface.jpg" alt="lynn surface" width="1000" height="784" /> Instalation at rendel &amp; spitz : the gap. it experiments with surface finish as a decoration.[/caption]</p>
<p>Lynn also uses algorithms to his advantage. The Kleiberg housing block in Amsterdam (2002) is a refurbishment of an older housing project made in a single building. After careful consideration of the brief, an algorithm was written which subdivided the interior into neighbourhoods accessed by escalators. The escalators were then supported by a ribbed system that also sheltered them. The form of these ribs was defined partially by a kit of parts approach, and partially by an algorithm which interrogated the two ribs preceding it and defined its shape depending on the tension and inertia of the shape as the algorithm was run from left to right, and then from right to left to finally define their shape. This results in the surface of the building having a visually well balanced façade, whose design incorporates structural concerns and also fits the program perfectly</p>
<p>[caption id="attachment_2006" align="alignnone" width="426"]<img class="wp-image-2006 size-full" src="{{ site.baseurl }}/assets/MACHINING-PATTERN.png" alt="MACHINING PATTERN" width="426" height="443" /> The two halves of this test board have the same shape in the computer, but it is interpreted differently by the cnc tool path program producing wildly different results[/caption]</p>
<p>Lynn’s approach of combining the power of software with the intricacies of real world fabrication leads to some f the path taken to get to the present position, change a variable and re-run, exactly as if it were a manually conceived design.</p>
<p>For architecture to continually evolve there needs to be a continual shedding of approaches. Marcus Novak makes the case succinctly when he asserts that the frank Gehry approach of manual modelling with subsequent computer construction was a fitting end to the twentieth century, but it has no place in the twenty first[1. Marcus Novac in Blobmiester].</p>
<p>The one thing that makes digital design stand out from what has preceded it is it’s ability to deal with complexity. Everything that can be done with a computer is also possible without it - a computer is just a box with wires that does maths, and as such can be replicated, given sufficient time with a pen and paper. Time is the crucial factor however, because as Gaudí proved with the Sagrada Família, there isn’t enough of it to do the calculations in a human lifetime (he died with less than half the church completed). The concept of finite element analysis was invented before computers, but was never pursued because it was too complex to do any sort of meaningful analysis manually. Calculating the algorithms that govern an emergent system, or the polynomial and simultaneous equations that govern a surface in a parametric design rely on the power of computers to do the calculations in a split second. This acceleration of complexity drives new forms and new organisational and structural systems to become a reality.</p>
<p>The area of design that has been spawned by computers is designing architecture in cyberspace. If we are to continue our integration with the internet and mobile communications at our current rate of consumption then it is conceivable that we will soon begin to ‘inhabit’ the internet rather than merely viewing it as we do now. As every generation of architects struggles with the question “…but is it architecture?” ours has the digital frontier to cross, and the associated removal of restrictions will doubtless produce some fascinating work as well as some interesting questions about how we conceive and inhabit our comparatively restrictive physical world.</p>
<h1 id="glossary">[glossary]</h1>
<h3>Rapid prototyping</h3>
<p><img class="alignnone size-full wp-image-2012" src="{{ site.baseurl }}/assets/rp-familia.png" alt="rp familia" /></p>
<p>Rapid prototyping is a general term applied to a range of manufacturing techniques used to produce a prototype of a computer model. The reason that rapid prototyping is used as opposed to more traditional manufacturing techniques is that there is no requirement for making jigs, or working out complicated tool paths. All the methods take very thin sections of the model and then rebuild them, so essentially they are stacked on top of each other.</p>
<h3>Selective Laser Sintering (sls)</h3>
<p><a href="/wordpress/wp-content/uploads/2015/10/steriolithography-2.png" rel="attachment wp-att-2013"><img class="alignnone size-full wp-image-2013" src="{{ site.baseurl }}/assets/steriolithography-2.png" alt="steriolithography 2" /></a></p>
<p>A very thin layer of fine polymer or metal particles is welded together using a laser beam in the pattern defined by a section through the computer model, the platform they are resting is then lowered by the thickness of the particle size, a new layer of particles is deposited and levelled off with a roller, and the process is repeated. When the particles melt they become connected to their neighbouring particles on the same layer and to those below them. sls can be used to produce fully dense working prototypes.</p>
<h3>Three Dimensional Physical Printing (3dpp)</h3>
<p><a href="/wordpress/wp-content/uploads/2015/10/rp-5.png" rel="attachment wp-att-2017"><img class="alignnone size-full wp-image-2017" src="{{ site.baseurl }}/assets/rp-5.png" alt="rp 5" /></a></p>
<p>An inkjet print head sprays a binder onto a powder layer that is arranged in the same way as in sls and glues the particles together layer by layer. The print head has several possible ink types and these can be configured to produce sections of the model that are soluble, thereby producing sacrificial supports etc.</p>
<h3>Laminated Object Modelling (lom)</h3>
<p><a href="/wordpress/wp-content/uploads/2015/10/rp3-laminate.png" rel="attachment wp-att-2015"><img class="alignnone size-full wp-image-2015" src="{{ site.baseurl }}/assets/rp3-laminate.png" alt="rp3 laminate" /></a></p>
<p>Layers of self adhesive paper are rolled over the bed of the machine, and the outline is traced with a laser cutter, the remaining paper it then cut into a cross hatched pattern and can be broken off once the model is complete. This technique is relatively fast, but it is limited in its ability to produce models with interiors as the paper would be trapped inside, whereas with a powder based method one could make a cage with a ball loose inside as the powder would act as a support and hold the ball in suspension until completion when the model could be removed and shaken to remove the trapped dust.</p>
<h3>Stereolithography including Photomasking</h3>
<p><a href="/wordpress/wp-content/uploads/2015/10/rp.png" rel="attachment wp-att-2014"><img class="alignnone size-full wp-image-2014" src="{{ site.baseurl }}/assets/rp.png" alt="rp" /></a></p>
<p>A polymer gel that is cured by exposure to light is contained in a tank similar to the ones used in powder based methods, the laser then tracks the shape required and the platen is lowered one layer and the process is repeated. The gel can produce objects in various colours including a clear resin[1. frame this month].  Photomasking uses the same system, but instead of the laser there is a large light covering the whole tank and a screen similar to the ones found in digital projectors that blocks the light where necessary.</p>
<h3>Fused deposition modelling (fdm)</h3>
<p>This method is similar to curled pottery or making things with glue gun glue. The deposition head extrudes a thin bead of pvc in the outline of the shape, and also in a crosshatch pattern in the interior for support, lowers the platen, and continues. As there is no powder or liquid to support the form as it is grown there is a secondary head which deposits a water soluble material that acts as a sprue.</p>
<h3>Computer model</h3>
<p>A computer model can take various forms; it can be purely mathematical, for example, the prediction of stock market trends, or the predictions of cod populations. In architectural terms however, the computer model is generally a representation in three dimensional virtual space of the intended form of the proposed structure. This can then have various physics calculations and geometrical transformations applied to it in order to achieve a structurally optimised or formally interesting design. The computer model can also be used to dramatically reduce design lead times and construction wastage by producing precise bills of quantities and doing, for instance, all the steelwork detailing, or automatically analysing egress routes for fire regulations. As the computer model is software based it can be passed around different specialists in its ‘soft’ form and they can modify the design reducing time consuming draughting. The building can be essentially perfect before it is committed to production.</p>
<h3>Spline</h3>
<p><img class="wp-image-2018 alignright" src="{{ site.baseurl }}/assets/dissertation_Page_69.jpg" alt="dissertation_Page_69" width="284" height="169" /></p>
<p>Splines are the most common method of defining curves in computer graphics. They were originally a thin piece of wood with weights attached to control the curves and were used in ship building to define the hull shapes. The weights have been replaced with control points which do the same thing in a computerised environment.</p>
<h3>Topology</h3>
<p>Put simply topology is a branch of geometry that isn’t concerned with scales or directions, but more with how things are connected together and if they have holes in them. A torus is a topological object because if scaled to an infinitely small scale the torus would always be bigger than the hole, and as such the torus would never disappear whereas a ball could continue to be scaled until it disappeared. The most commonly cited topological transformation is from a donut to a tea cup, as the donut already has a hole in it, it is simply a case of moving the matter around the hole to change the form. One side of the hole gets very thin and becomes the handle and the other side becomes much larger and gets a dent in the top and becomes the bowl. The donut and the cup are topologically identical[1. for more information on topology visit http://www.shef.ac.uk/nps/Wurble.html (20-01-2005) and read (flatterland chapter ref)].</p>
<h3>Möbius strip</h3>
<p><img class="alignnone size-full wp-image-2020" src="{{ site.baseurl }}/assets/mobius.png" alt="mobius" /></p>
<p>The Möbius strip is a mathematical curiosity in that it is a topological surface with only one side. Discovered in the nineteenth century by August Ferdinand Möbius. It is often explained using a paper strip which has been given a half twist and stuck end to end in a loop. This description can lead to confusion when trying to conceptualise it later on as the paper strip is a thin three dimensional object, it has sides and is essentially a flattened torus, whereas the Möbius strip is actually a two dimensional object that exists in three dimensional space.</p>
<h3>Klein Bottle</h3>
<p><img class=" wp-image-2019 alignright" src="{{ site.baseurl }}/assets/klein31.png" alt="klein3[1]" width="222" height="200" /></p>
<p>In 1882 Felix Klein devised a Möbius strip with an extra dimension, a Möbius surface essentially, this was eventually called a Klein Bottle. In contrast to the paper approximation of the Möbius strip provides great surprise and delight in those who encounter it, the Klein bottle is quite disappointing, the point where the surface intersects itself makes the three dimensional form seem not to work, however if you consider the Möbius strip to be a two dimensional surface that needs to exist in three dime<p><img class="wp-image-2010 alignright" src="{{ site.baseurl }}/assets/spaceframe.jpg" alt="spaceframe" width="301" height="177" />Robert Aish of Bentley Systems draws a graph of the idealised design process, a straight line from inception to completion. He then overlays the realistic path taken by a design as its characteristics are modified, advanced, regressed the path taken to get to the present position, change a variable and re-run, exactly as if it were a manually conceived design.</p>
<p>For architecture to continually evolve there needs to be a continual shedding of approaches. Marcus Novak makes the case succinctly when he asserts that the frank Gehry approach of manual modelling with subsequent computer construction was a fitting end to the twentieth century, but it has no place in the twenty first[^23].</p>
<p>The one thing that makes digital design stand out from what has preceded it is it’s ability to deal with complexity. Everything that can be done with a computer is also possible without it - a computer is just a box with wires that does maths, and as such can be replicated, given sufficient time with a pen and paper. Time is the crucial factor however, because as Gaudí proved with the Sagrada Família, there isn’t enough of it to do the calculations in a human lifetime (he died with less than half the church completed). The concept of finite element analysis was invented before computers, but was never pursued because it was too complex to do any sort of meaningful analysis manually. Calculating the algorithms that govern an emergent system, or the polynomial and simultaneous equations that govern a surface in a parametric design rely on the power of computers to do the calculations in a split second. This acceleration of complexity drives new forms and new organisational and structural systems to become a reality.</p>
<p>The area of design that has been spawned by computers is designing architecture in cyberspace. If we are to continue our integration with the internet and mobile communications at our current rate of consumption then it is conceivable that we will soon begin to ‘inhabit’ the internet rather than merely viewing it as we do now. As every generation of architects struggles with the question “…but is it architecture?” ours has the digital frontier to cross, and the associated removal of restrictions will doubtless produce some fascinating work as well as some interesting questions about how we conceive and inhabit our comparatively restrictive physical world.</p>
<h1 id="glossary">[glossary]</h1>
<h3>Rapid prototyping</h3>
<p><img class="alignnone size-full wp-image-2012" src="{{ site.baseurl }}/assets/rp-familia.png" alt="rp familia" /></p>
<p>Rapid prototyping is a general term applied to a range of manufacturing techniques used to produce a prototype of a computer model. The reason that rapid prototyping is used as opposed to more traditional manufacturing techniques is that there is no requirement for making jigs, or working out complicated tool paths. All the methods take very thin sections of the model and then rebuild them, so essentially they are stacked on top of each other.</p>
<h3>Selective Laser Sintering (sls)</h3>
<p><a href="/wordpress/wp-content/uploads/2015/10/steriolithography-2.png" rel="attachment wp-att-2013"><img class="alignnone size-full wp-image-2013" src="{{ site.baseurl }}/assets/steriolithography-2.png" alt="steriolithography 2" /></a></p>
<p>A very thin layer of fine polymer or metal particles is welded together using a laser beam in the pattern defined by a section through the computer model, the platform they are resting is then lowered by the thickness of the particle size, a new layer of particles is deposited and levelled off with a roller, and the process is repeated. When the particles melt they become connected to their neighbouring particles on the same layer and to those below them. sls can be used to produce fully dense working prototypes.</p>
<h3>Three Dimensional Physical Printing (3dpp)</h3>
<p><a href="/wordpress/wp-content/uploads/2015/10/rp-5.png" rel="attachment wp-att-2017"><img class="alignnone size-full wp-image-2017" src="{{ site.baseurl }}/assets/rp-5.png" alt="rp 5" /></a></p>
<p>An inkjet print head sprays a binder onto a powder layer that is arranged in the same way as in sls and glues the particles together layer by layer. The print head has several possible ink types and these can be configured to produce sections of the model that are soluble, thereby producing sacrificial supports etc.</p>
<h3>Laminated Object Modelling (lom)</h3>
<p><a href="/wordpress/wp-content/uploads/2015/10/rp3-laminate.png" rel="attachment wp-att-2015"><img class="alignnone size-full wp-image-2015" src="{{ site.baseurl }}/assets/rp3-laminate.png" alt="rp3 laminate" /></a></p>
<p>Layers of self adhesive paper are rolled over the bed of the machine, and the outline is traced with a laser cutter, the remaining paper it then cut into a cross hatched pattern and can be broken off once the model is complete. This technique is relatively fast, but it is limited in its ability to produce models with interiors as the paper would be trapped inside, whereas with a powder based method one could make a cage with a ball loose inside as the powder would act as a support and hold the ball in suspension until completion when the model could be removed and shaken to remove the trapped dust.</p>
<h3>Stereolithography including Photomasking</h3>
<p><a href="/wordpress/wp-content/uploads/2015/10/rp.png" rel="attachment wp-att-2014"><img class="alignnone size-full wp-image-2014" src="{{ site.baseurl }}/assets/rp.png" alt="rp" /></a></p>
<p>A polymer gel that is cured by exposure to light is contained in a tank similar to the ones used in powder based methods, the laser then tracks the shape required and the platen is lowered one layer and the process is repeated. The gel can produce objects in various colours including a clear resin[^24].  Photomasking uses the same system, but instead of the laser there is a large light covering the whole tank and a screen similar to thlities of it are huge, the only thing holding it back is it’s prohibitive price, an average set up cost for one workstation is at least £20 000.</p>
<h3>cnc</h3>
<p><img class="alignnone size-full wp-image-2025" src="{{ site.baseurl }}/assets/catia3.jpg" alt="catia3" /></p>
<p>computer numerical control. Computer controlled manufacturing machines are described as cnc machines because a set of numerical instructions describes the tool paths. Initially these were set out on punch cards, but these days they are all digital. The most useful machines as far as architectural applications are concerned are five axis milling machines, these have three linear axis – two horizontal, and one vertical, and two rotational axis or planes. This allows the head to rotate to present different parts of the tool to the surface, which allows for complex geometry, and faster runs as the job needs fewer clamping changes and the tool head can be moved out of the way if necessary.</p>
<h3>Finite element analysis - fea</h3>
<p><img class="alignnone size-full wp-image-2024" src="{{ site.baseurl }}/assets/ansys-d-tower.jpg" alt="ansys d tower" /></p>
<p>This is a method of calculating the effects of a physical intervention (stress, heat, etc.) on an object. Invented in 1943[1. http://www.sv.vt.edu/classes/MSE2094_NoteBook/97ClassProj/num/widas/history.html] it was used for very limited analysis of deformations, it essentially involves breaking the object into sections, finite elements. Then by using a very complex matrix and even more complex series of calculations on that matrix the interaction between the elements is established. fea was invented before the advent of digital computers, didn’t really take off until the advent of super computers due to the huge calculations involved in producing results. The main fea program these days is ansys[1. For more information on ansys visit http://www.ansys.com/], this was used to calculate the structure and apply forces such as wind loading to the <span class="small-caps">nox</span> D-Tower.</p>
<h3>Morphing</h3>
<p><img class="wp-image-2027 alignright" src="{{ site.baseurl }}/assets/darcy.png" alt="darcy" width="300" height="393" /></p>
<p>A procedure that first gained fame in the 1991 film Terminator 2-–Judgement Day[1. terminator 2] as the metal terminator turned into a pool of molten metal and then back into a humanoid robot. First described by D’arcy Thompson in his 1918 book ‘on growth and form’ where he demonstrated the evolutionary lineage of skeletal parts by distorting a grid over them, and then continuing the distortion to predict the next step.</p>
<h3>Parametric design</h3>
<p>method of design where the dimensions of an object are defined, not as an absolute numerical value, but in relation to another value, for instance a rectangle where the one side is x and the other is 2x. As parameters can be fixed or limited parametric algorithms can be linked to configurations and used to mass-customise items such as running shoes[1. Nike ID is a service that allows customers to use a configurator to design their own trainers with customised colour schemes, sole densities and embroidery. Visit http://www.nikeid.nike.com] or even houses[1. detail micro architecture].</p>
<h3>Artificial intelligence</h3>
<p>a general name applied to a system that displays signs of sentient thought. There are various ways of achieving artificial intelligence, but the general principle is that it is based on a bottom up approach in that the system is given a very set of rules, and it is then left to learn.</p>
<h3>Rendering</h3>
<p>a computer process that calculates how the objects in a scene interact with light, and then produces a realistic image of the scene. The objects are assigned material properties that define how the light will interact with them, and the resulting calculations take into account all these factors to produce the image.</p>
<h3>vr</h3>
<p>virtual reality is an attempt to create a simulated immersion in an environment. The Victorians produced stereoscopic images by taking two images from marginally different viewpoints, and the using a special viewer showed one to each eye, therefore fooling the viewers optical system into thinking it was seeing a three dimensional scene due to an illusion of binocular vision. This principle has been taken on much further, and now the photographs can be replaced by moving images, and these can be linked to a scene that can be navigated around at will. The main constraint in the immersive experience is that only two senses are engaged (sound and vision), and in order to engage the other three is still beyond our capabilities.</p>
<h3>Vector</h3>
<p>a vector contains magnitude (size – speed, length etc.) and direction, so it can describe movement, or a line. Vector graphics is made up of a series of lines which are defined mathematically rather than being described by a series of pixels.</p>
<h3>Turing machine</h3>
<p><img class="size-full wp-image-2026 alignright" src="{{ site.baseurl }}/assets/turing.png" alt="turing" /></p>
<p>Alan Turing was a mathematician who worked with the British army to crack the German Enigma code during the Second World War. He designed the first digital computers and used them in code breaking. A Turing machine isn’t actually a physical object, but rather a mathematical concept that describes the series of events that would happen in a notional computer to compute a problem[1. For a detailed explanation of the concepts behind the Turing machine visit http://plato.stanford.edu/entries/turing-machine/ 20-01-2005].</p>
<h3>Scan</h3>
<p>to scan something generally means to digitise it’s coordinate data, if it is a two dimensional object then the scanner will measure the colour of a set number of points (the number being defined by the resolution i.e. 600 dots per inch, so it will scan 600 points per linear inch) and then reconstruct the data into an image in the computer. If the object is three dimensional then the scanner will measure its form by using either a touch probe which measures the object by touching it, or with lasers, and sometimes also its colour. The date is then reconstructed as a point cloud in the computer and a surface which corresponds to those points is generated.</p>
<h3>Hyper[cube]</h3>
<p><a href="/wordpress/wp-content/uploads/2015/10/hypercube.png" rel="attachment wp-att-2028"><img class="alignnone size-full wp-image-2028" src="{{ site.baseurl }}/assets/hypercube.png" alt="hypercube" /></a></p>
<p>[caption id="attachment_2029" align="alignright" width="351"]<img class="wp-image-2029" src="{{ site.baseurl }}/assets/corpus-hypercubus.jpg" alt="corpus hypercubus" width="351" height="558" /> Dali : Corpus Hypercubus[/caption]</p>
<p>understanding four dimensional concepts is easier if you start with lower dimensions and extrapolate. If you start with a point, a zero dimensional object, and add a dimension, you must add a point for every existing point, you get a line, a one dimensional object. This line is a hyperpoint. Then if you add another dimension to make the line two dimensional then you have a square plane, a hyperline. In adding another dimension to make a three dimensional cube you have created a hypersquare. These terms seem a little ridiculous when applied to objects which we already have names for because we are all familiar with them, but when we add another dimension to a cube we get a hypercube, which we cannot visualise because we do not have the apparatus to do so, but it has captured the imagination of many artists and mathematicians. Dali’s Corpus Hypercubus is a prime example, it shows one of the possible ‘unfoldings’ of a hypercube, but as the human visual system is only equipped to deal with two dimensional images, a perspective of a three dimensional object can be projected onto a two dimensional plane, but a four dimensional object is more difficult.<br />
The same principle can be applied to any shape to produce hyper-pentagons or hyper-spheres, and as such any three dimensional solid can be considered the hyper surface of a four dimensional object.</p>
<h3>Meta</h3>
<p>meta is a prefix that denotes a level of transcendence, for example in a cube the vertices that extend in the third dimensional are meta points. It can be simplified to ‘about’, meta data is data about data (98% of all statistics are made up)</p>
<h3>Maya</h3>
<p>Maya is Alias Wavefront’s[1. For more information on Maya visit http://www.alias.com/eng/products-services/maya/index.shtml] three dimensional animation and modelling product. It was one of the first programs to include a cloth simulator, and has been used to model tensile structures because of this. It also has a programming language which is widely used to create design algorithms called mel (Maya Embedded Language) it’s use is so widespread due to it’s relative ease of use[1. For some examples of mel in use visit http://www.arch.columbia.edu/gsap/1747].</p>
<h3>3D Studio Max</h3>
<p>3D Studio Max, or Max as it’s commonly called is made by discreet[1. For more information on 3DS Max visit http://www4.discreet.com/3dsmax/], a subsidiary of AutoDesk[1. For more information on http://www.autodesk.co.uk/adsk/servlet/index?siteID=452932&amp;id=4013256] (who make AutoCAD) but they try and distance themselves as much as possible from their parent company. The program is used a lot in three dimensional graphics for films, and recent versions have been boosting its architectural visualisation abilities with ready made components. It has a built in programming language called Max Script, but it is relatively hard to learn, and as such hasn’t found as much favour as other scripting languages (mel for example). It also has a range of dynamics tools which can simulate cloth and mechanical assemblies.</p>
<h3>Asymptote</h3>
<p>A curve which continually tends towards an axis, and becomes infinitesimally close but never actually reaches it.</p>
<h3>gc</h3>
<p>Generative components is Bentley Systems new parametric design software application. It is very powerful and allows designs to be reached by inputting constraints and sets of logical rules. It will produce structu<p>In 1882 Felix Klein devised a Möbius strip with an extra dimension, a Möbius surface essentially, this was eventually called a Klein Bottle. In contrast to the paper approximation of the Möbius strip provides great surprise and delight in those who encounter it, the Klein bottle is quite disappointing, the point where the surface intersects itself makes the three dimensional form seem not to work, however if you consider the Möbius strip to be a two dimensional surface that needs to exist in three dimelities of it are huge, the only thing holding it back is it’s prohibitive price, an average set up cost for one workstation is at least £20 000.</p>
<h3>cnc</h3>
<p><img class="alignnone size-full wp-image-2025" src="{{ site.baseurl }}/assets/catia3.jpg" alt="catia3" /></p>
<p>computer numerical control. Computer controlled manufacturing machines are described as cnc machines because a set of numerical instructions describes the tool paths. Initially these were set out on punch cards, but these days they are all digital. The most useful machines as far as architectural applications are concerned are five axis milling machines, these have three linear axis – two horizontal, and one vertical, and two rotational axis or planes. This allows the head to rotate to present different parts of the tool to the surface, which allows for complex geometry, and faster runs as the job needs fewer clamping changes and the tool head can be moved out of the way if necessary.</p>
<h3>Finite element analysis - fea</h3>
<p><img class="alignnone size-full wp-image-2024" src="{{ site.baseurl }}/assets/ansys-d-tower.jpg" alt="ansys d tower" /></p>
<p>This is a method of calculating the effects of a physical intervention (stress, heat, etc.) on an object. Invented in 1943[^26] it was used for very limited analysis of deformations, it essentially involves breaking the object into sections, finite elements. Then by using a very complex matrix and even more complex series of calculations on that matrix the interaction between the elements is established. fea was invented before the advent of digital computers, didn’t really take off until the advent of super computers due to the huge calculations involved in producing results. The main fea program these days is ansys[1. For more information on ansys visit http://www.ansys.com/], this was used to[^27] to the <span class="small-caps">nox</span> D-Tower.</p>
<h3>Morphing</h3>
<p><img class="wp-image-2027 alignright" src="{{ site.baseurl }}/assets/darcy.png" alt="darcy" width="300" height="393" /></p>
<p>A procedure that first gained fame in the 1991 film Terminator 2-–Judgement Day[^28] as the metal terminator turned into a pool of molten metal and then back into a humanoid robot. First described by D’arcy Thompson in his 1918 book ‘on growth and form’ where he demonstrated the evolutionary lineage of skeletal parts by distorting a grid over them, and then continuing the distortion to predict the next step.</p>
<h3>Parametric design</h3>
<p>method of design where the dimensions of an object are defined, not as an absolute numerical value, but in relation to another value, for instance a rectangle where the one side is x and the other is 2x. As parameters can be fixed or limited parametric algorithms can be linked to configurations and used to mass-customise items such as running shoes[^29] or even houses[1. detail micro architecture].</p>
[^30]<h3>Artificial intelligence</h3>
<p>a general name applied to a system that displays signs of sentient thought. There are various ways of achieving artificial intelligence, but the general principle is that it is based on a bottom up approach in that the system is given a very set of rules, and it is then left to learn.</p>
<h3>Rendering</h3>
<p>a computer process that calculates how the objects in a scene interact with light, and then produces a realistic image of the scene. The objects are assigned material properties that define how the light will interact with them, and the resulting calculations take into account all these factors to produce the image.</p>
<h3>vr</h3>
<p>virtual reality is an attempt to create a simulated immersion in an environment. The Victorians produced stereoscopic images by taking two images from marginally different viewpoints, and the using a special viewer showed one to each eye, therefore fooling the viewers optical system into thinking it was seeing a three dimensional scene due to an illusion of binocular vision. This principle has been taken on much further, and now the photographs can be replaced by moving images, and these can be linked to a scene that can be navigated around at will. The main constraint in the immersive experience is that only two senses are engaged (sound and vision), and in order to engage the other three is still beyond our capabilities.</p>
<h3>Vector</h3>
<p>a vector contains magnitude (size – speed, length etc.) and direction, so it can describe movement, or a line. Vector graphics is made up of a series of lines which are defined mathematically rather than being described by a series of pixels.</p>
<h3>Turing machine</h3>
<p><img class="size-full wp-image-2026 alignright" src="{{ site.baseurl }}/assets/turing.png" alt="turing" /></p>
<p>Alan Turing was a mathematician who worked with the British army to crack the German Enigma code during the Second World War. He designed the first digital computers and used them in code breaking. A Turing machine isn’t actually a physical object, but rather a mathematical concept that describes the series of events that would happen in a notional computer to compute a problem[^31].</p>
<h3>Scan</h3>
<p>to scan something generally means to digitise it’s coordinate data, if it is a two dimensional object then the scanner will measure the colour of a set number of points (the number being defined by the resolution i.e. 600 dots per inch, so it will scan 600 points per linear inch) and then reconstruct the data into an image in the computer. If the object is three dimensional then the scanner will measure its form by using either a touch probe which meas<p>Generative components is Bentley Systems new parametric design software application. It is very powerful and allows designs to be reached by inputting constraints and sets of logical rules. It will produce structu

[^1]: In 1965 Gordon Moore predicted that the number of transistors per integrated circuit would double every 2 years. This has remained true ever since, however we are reaching the limits of our current manufacturing techniques capacity, but this has happened before and a new technology has allowed the trend to continue unabated. For more information see http://www.intel.com/research/silicon/mooreslaw.htm 21-01-2005

[^2]: Manual de Landa describes the progression of history in European culture as mineralization, whereby towns which would originally have been built and defended with wooden structures became more and more dependant on their architecture as means of defence. Manual De Landa 1000 years of non linear history.

[^3]: for a mathematical explanation of catenary curves visit http://mathworld.wolfram.com/Catenary.html

[^4]: Alan Turing ref, probably the Mathland book

[^5]: Sunday times culture magazine 9-1-2005 page 19 Hugh Pearman Alsop’s fabled buildings

[^6]: computers in design quote and ref

[^7]: http://www.3ds.com/news-events/press-room/release/368/1/?encryptionKey=&amp;cHash=f81892a030 12-01-2004

[^8]: 160 <span class="small-caps">nox</span> book

[^9]: a house where sounds live. Public art work for industrieschap Ekkersrijt, in collaboration with composer Edwin van der Heide, Son en Breugel, the Netherlands 2000-04. 

[^10]: p343 nox book

[^11]: pi film

[^12]: p365 nox book

[^13]: p5 ad

[^14]: http://www.beart.org.uk/Emergent/ 11-01-2005

[^15]: p5 AD on emergence

[^16]: http://www.biologie.uni-hamburg.de/b-online/e32/32d.htm 12-01-04

[^17]: blob page 219

[^18]: For more information on Koan visit http://www.sseyo.com/products/koanpro/index.html

[^19]: in Blobmeister (full ref page 227) he cites Dawkins (an evolutionary biologist who theorises that evolution has no direction, but rather it exploits opportunities as they arise and the organisms fitness is relevant to it’s time), Shannon’s information theory (a way of measuring the volume of data that can be passed through a given channel) and Pareto optimality (a theory that allows a group of individuals to coexist by making decisions that will be benificial to the group ratehr than directy to that individual)

[^20]: ref architectural labs conversation in the middle

[^21]: http://www.graphisoft.com/products/archicad/

[^22]: For more information on Architectural Desktop visit http://www.autodesk.co.uk/adsk/servlet/index?siteID=452932&amp;id=4014829

[^23]: Marcus Novac in Blobmiester

[^24]: frame this month

[^25]: for more information on topology visit http://www.shef.ac.uk/nps/Wurble.html (20-01-2005) and read (flatterland chapter ref)

[^26]: http://www.sv.vt.edu/classes/MSE2094_NoteBook/97ClassProj/num/widas/history.html

[^27]: For more information on ansys visit http://www.ansys.com/

[^28]: terminator 2

[^29]: Nike ID is a service that allows customers to use a configurator to design their own trainers with customised colour schemes, sole densities and embroidery. Visit http://www.nikeid.nike.com

[^30]: detail micro architecture

[^31]: For a detailed explanation of the concepts behind the Turing machine visit http://plato.stanford.edu/entries/turing-machine/ 20-01-2005

[^32]: For more information on Maya visit http://www.alias.com/eng/products-services/maya/index.shtml

[^33]: For some examples of mel in use visit http://www.arch.columbia.edu/gsap/1747

[^34]: For more information on 3DS Max visit http://www4.discreet.com/3dsmax/

[^35]: For more information on http://www.autodesk.co.uk/adsk/servlet/index?siteID=452932&amp;id=4013256

